{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_val = np.moveaxis(x_train, [3, 1, 2], [1, 2, 3]).astype('float32')[45000:50000]\n",
    "x_train = np.moveaxis(x_train, [3, 1, 2], [1, 2, 3]).astype('float32')[:45000]\n",
    "x_test = np.moveaxis(x_test, [3, 1, 2], [1, 2, 3]).astype('float32')\n",
    " \n",
    "x_train /= 255\n",
    "x_val /= 255\n",
    "x_test /= 255\n",
    "\n",
    "    \n",
    "#８〜９ラベルを１〜７に\n",
    "y_val = y_train.reshape(-1).astype('long')[45000:50000]\n",
    "y_val_rand = copy.copy(y_val)\n",
    "y_val_rand[y_val_rand > 7] = np.random.randint(0,8,len(y_val_rand[y_val_rand > 7]))\n",
    "\n",
    "y_train = y_train.reshape(-1).astype('long')[:45000]\n",
    "y_train_rand = copy.copy(y_train)\n",
    "noisesample = np.where(y_train_rand > 7)[0]\n",
    "cleansample = np.where(y_train_rand <= 7)[0]\n",
    "y_train_rand[y_train_rand > 7] = np.random.randint(0,8,len(noisesample))\n",
    "                                                   \n",
    "dfnoise = pd.DataFrame([noisesample])\n",
    "dfclean = pd.DataFrame([cleansample])                                                                     \n",
    "    \n",
    "y_test = y_test.reshape(-1).astype('long')\n",
    "\n",
    "testsample = np.where(y_test <= 7)[0]\n",
    "y_test = y_test[testsample]\n",
    "x_test = x_test[testsample]\n",
    "\n",
    "ds_like = data.TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train_rand))\n",
    "dataloader_like = data.DataLoader(dataset=ds_like, batch_size=1000, shuffle=False)\n",
    "\n",
    "ds_val = data.TensorDataset(torch.from_numpy(x_val), torch.from_numpy(y_val_rand))\n",
    "dataloader_val = data.DataLoader(dataset=ds_val, batch_size=128, shuffle=False)\n",
    "\n",
    "ds_test = data.TensorDataset(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
    "dataloader_test = data.DataLoader(dataset=ds_test, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.mobilenet_v2(progress=True, **{\"num_classes\": 8}).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = 0\n",
    " \n",
    "def train(epoch, writer):\n",
    "    model.train()\n",
    "    scheduler.step()    \n",
    "    \n",
    "    steps = len(ds_sel)//batch_size\n",
    "    for step, (images, labels) in enumerate(dataloader_sel, 1):\n",
    "        global global_step\n",
    "        global_step += 1\n",
    " \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    " \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        if step % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' % (epoch, epochs, step, steps, loss.item()))\n",
    "            writer.add_scalar('train/train_loss', loss.item() , global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def softmax(Llist):\n",
    "\n",
    "    exp_x = np.exp(Llist)    \n",
    "    y = exp_x / np.array([np.sum(exp_x,axis=1)]).T    \n",
    "    return np.max(y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expert(epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    labelcheck = []\n",
    "    with torch.no_grad():\n",
    "        p_list = []\n",
    "        for step,(images, labels) in enumerate(dataloader_like,1):\n",
    "            labelinf = np.zeros(len(labels))\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "           \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "           \n",
    "            p = softmax([list(map(float,i)) for i in list(outputs)])\n",
    "            p_list.extend(p)\n",
    "            \n",
    "            prelist = list(map(int,predicted))\n",
    "            lablist = list(map(int,labels))\n",
    "            \n",
    "            labelinf[np.where(np.array(prelist) == np.array(lablist))[0]] = 1\n",
    "            labelinf[np.where(np.array(prelist) != np.array(lablist))[0]] = -1\n",
    "            \n",
    "            labelcheck.extend(labelinf)\n",
    "            \n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print(\"PP:\"+str(p[0]))\n",
    "            \n",
    "        train_acc = len(np.where(np.array(labelcheck)==1)[0])/len(labelcheck)\n",
    "        loss_list = (1 - np.array(labelcheck)*(1 - np.array(p_list)))/2\n",
    "        print(\"Tra Acc : %.4f\" % (train_acc))\n",
    "    \n",
    "    return np.array(loss_list),train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(epoch,writer):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in dataloader_val:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    " \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    " \n",
    "    print(\"Val Acc : %.4f\" % (correct/total))\n",
    "    writer.add_scalar('eval/val_acc', correct*100/total, epoch)\n",
    "    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(epoch,writer):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in dataloader_test:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    " \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            #print(predicted)\n",
    "            #print(outputs)\n",
    " \n",
    "    print(\"Test Acc : %.4f\" % (correct/total))\n",
    "    writer.add_scalar('eval/val_acc', correct*100/total, epoch)\n",
    "    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "from statistics import mean\n",
    "import random\n",
    "import pandas as pd\n",
    "writer = SummaryWriter()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "\n",
    "n = len(y_train_rand)\n",
    "\n",
    "\n",
    "M = 4*np.log(n)\n",
    "β = 1/(1+np.sqrt(2*np.log(n)/M))\n",
    "\n",
    "for k in [22500,27000,31500,36000,40500,45000]:\n",
    "    \n",
    "    eta = np.sqrt(k*epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    \n",
    "    percent = (100*k)/45000\n",
    "\n",
    "    train_acclist = []\n",
    "    val_acclist = []\n",
    "    test_acclist = []\n",
    "    cumloss_list = []\n",
    "\n",
    "    xt = np.array(random.sample(range(0,n),k=k))\n",
    "    \n",
    "    if k < 45000:\n",
    "        \n",
    "        cumloss = np.zeros(n)\n",
    "        c_map = np.array([1/n for j in range(n)])\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "    \n",
    "            xt = np.sort(xt)\n",
    "            c = np.zeros(n)\n",
    "            c[xt] = 1\n",
    "            c_map = np.vstack((c_map,c))\n",
    "    \n",
    "            ds_sel = data.TensorDataset(torch.from_numpy(x_train[xt]), torch.from_numpy(y_train_rand[xt]))\n",
    "            dataloader_sel = data.DataLoader(dataset=ds_sel, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "            train(epoch, writer)\n",
    "            loss_list,train_acc = expert(epoch)\n",
    "            cumloss = cumloss + loss_list\n",
    "            cumloss_list.append(cumloss)\n",
    "            normalnoise = np.random.normal(0,0.00001,(n))\n",
    "            virtualloss = cumloss + eta*normalnoise \n",
    "            xt = np.argsort(virtualloss)[:k]\n",
    "            \n",
    "            \n",
    "            val_acc = eval(epoch, writer)\n",
    "            test_acc = test(epoch, writer)\n",
    "    \n",
    "           \n",
    "            train_acclist.append(train_acc)\n",
    "            val_acclist.append(val_acc)\n",
    "            test_acclist.append(test_acc)\n",
    "    \n",
    "    elif k == 45000:\n",
    "\n",
    "        ds_sel = data.TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train_rand))\n",
    "        dataloader_sel= data.DataLoader(dataset=ds_sel, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "            train(epoch, writer)\n",
    "            likelihoodlist,train_acc = expert(epoch)\n",
    "            val_acc = eval(epoch, writer)\n",
    "            test_acc = test(epoch, writer)\n",
    "    \n",
    "            train_acclist.append(train_acc)\n",
    "            val_acclist.append(val_acc)\n",
    "            test_acclist.append(test_acc)\n",
    "    \n",
    "writer.close()\n",
    "print(\"END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
